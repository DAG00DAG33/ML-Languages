{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PytorchCheatSheet",
      "provenance": [],
      "collapsed_sections": [
        "1LhHPBuNmBoj",
        "mCnEER85PUL4"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DAG00DAG33/ML-Languages/blob/master/Pytorch/PytorchCheatSheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zE_kq_KfWB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import torch #\n",
        "import torch.nn as nn #\n",
        "import torch.optim as optim #\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image #\n",
        "import matplotlib.pyplot as plt #\n",
        "\n",
        "import torchvision.transforms as transforms #\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCf6RJ-nOyU8",
        "colab_type": "text"
      },
      "source": [
        "#Load Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LhHPBuNmBoj",
        "colab_type": "text"
      },
      "source": [
        "## Load image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS2afe6gfpoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imsize = 512\n",
        "loader = transforms.Compose([\n",
        "    transforms.Resize(imsize),  # scale imported image\n",
        "    transforms.ToTensor()])  # transform it into a torch tensor\n",
        "    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "\n",
        "def image_loader(image_name):\n",
        "    image = Image.open(image_name)\n",
        "    # fake batch dimension required to fit network's input dimensions\n",
        "    image = loader(image).unsqueeze(0)\n",
        "    return image.to(device, torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_66S7GFa4WvS",
        "colab_type": "text"
      },
      "source": [
        "##Data pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCnEER85PUL4",
        "colab_type": "text"
      },
      "source": [
        "###de archivo, CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayVG_2v24chW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk1wIa4XPcFd",
        "colab_type": "text"
      },
      "source": [
        "###De base np array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWiImg1tPjFA",
        "colab_type": "text"
      },
      "source": [
        "Hay que ver como unir al transformer para data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddKvQK7aqnYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cambio de los ejes para Chanel first (-1, 3, 64, 64)\n",
        "X_train = np.moveaxis(X_train, 3, 1)\n",
        "X_test = np.moveaxis(X_test, 3, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X7wOVKJdUr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensor_x_train = torch.stack([torch.Tensor(X_train[i]) for i in range(X_train.shape[0])]) # transform to torch tensors\n",
        "tensor_y_train = torch.stack([torch.Tensor(Y_train[i]) for i in range(Y_train.shape[0])])\n",
        "\n",
        "my_train_dataset = torch.utils.data.TensorDataset(tensor_x_train,tensor_y_train) # create your datset\n",
        "trainloader = torch.utils.data.DataLoader(my_train_dataset, batch_size=BATCH_SIZE, shuffle=True) # create your dataloader\n",
        "\n",
        "\n",
        "tensor_x_test = torch.stack([torch.Tensor(X_test[i]) for i in range(X_test.shape[0])]) # transform to torch tensors\n",
        "tensor_y_test = torch.stack([torch.Tensor(Y_test[i]) for i in range(Y_test.shape[0])])\n",
        "\n",
        "my_test_dataset = torch.utils.data.TensorDataset(tensor_x_test,tensor_y_test) # create your datset\n",
        "testloader = torch.utils.data.DataLoader(my_test_dataset, batch_size=BATCH_SIZE, shuffle=True) # create your dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkQr6VbXgS9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVFeCIJQfOgU",
        "colab_type": "text"
      },
      "source": [
        "# Show image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUJAEvGSeyLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unloader = transforms.ToPILImage()  # reconvert into PIL image\n",
        "\n",
        "def imshow(tensor, title=None):\n",
        "    plt.figure()\n",
        "    image = tensor.cpu().clone()  # we clone the tensor to not do changes on it\n",
        "    if len(image.shape) == 4:\n",
        "      image = image.squeeze(0)      # remove the fake batch dimension if needed\n",
        "    image = unloader(image)\n",
        "    plt.imshow(image)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "\n",
        "\n",
        "\n",
        "imshow(images[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C0TuVEDmLDr",
        "colab_type": "text"
      },
      "source": [
        "# Import VGG model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2UEOLj3mAm0",
        "colab_type": "code",
        "outputId": "d0683fae-2053-4d6d-ed53-780db7a62499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "cnn = models.vgg19(pretrained=True).features.to(device).eval()\n",
        "\n",
        "\"\"\"Hi, These two have different goals: model.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in \n",
        "eval mode instead of training mode. torch.no_grad() impacts the autograd engine and deactivate it. It will reduce memory usage and speed up\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi, These two have different goals: model.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in \\neval mode instead of training mode. torch.no_grad() impacts the autograd engine and deactivate it. It will reduce memory usage and speed up'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRdf-LTDqX_0",
        "colab_type": "text"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr8DWTKDqaJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm__7cy9Qhq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Reshape(nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = args\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(self.shape)\n",
        "\n",
        "#Ejemplo de como ponerlo:\n",
        "#Reshape(-1,240,4,4) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-M-fh3Kqc2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes, dropout_prob=0.3):\n",
        "        super(Net, self).__init__()\n",
        "        self.pipe = nn.Sequential(\n",
        "            nn.BatchNorm2d(3),\n",
        "            nn.Conv2d(in_channels=3, out_channels=8,\n",
        "                      kernel_size=5, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=8, out_channels=16,\n",
        "                      kernel_size=5, stride=2, padding=1),\n",
        "            Flatten(),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(3840)\n",
        "            nn.Linear(3600, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, num_classes),\n",
        "            nn.Dropout(p=dropout_prob),\n",
        "            #nn.Sigmoid(),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pipe(x)\n",
        "\n",
        "net = Net(6).to(device)\n",
        "net(images.to(device))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oi6flBfCE5R",
        "colab_type": "text"
      },
      "source": [
        "## summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvL-JgkGCGCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary  import summary\n",
        "summary(net, (3,64,64))  #summary(model, (inputShape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KRKKeqjYR_v",
        "colab_type": "text"
      },
      "source": [
        "#Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxEv6-JkYZfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CHK_PATH = '/content/drive/My Drive/ML/Lenguajes/Pytorch/checkpoints/'\n",
        "cuda = torch.cuda.is_available()\n",
        "if cuda:\n",
        "    checkpoint = torch.load(CHK_PATH + 'checkpoint.pth.tar')\n",
        "else:\n",
        "    # Load GPU model on CPU\n",
        "    checkpoint = torch.load(resume_weights,\n",
        "                            map_location=lambda storage,\n",
        "                            loc: storage)\n",
        "start_epoch = checkpoint['epoch']\n",
        "best_epochLoss = checkpoint['best_epochLoss']\n",
        "encoder.load_state_dict(checkpoint['encoder_dict'])\n",
        "decoder.load_state_dict(checkpoint['decoder_dict'])\n",
        "losses = checkpoint['losses']\n",
        "print(\"=> loaded checkpoint '{}' (trained for {} epochs)\".format(\"a\", checkpoint['epoch']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB0h4JTmn6tp",
        "colab_type": "text"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKvG2SOiUYNt",
        "colab_type": "text"
      },
      "source": [
        "##Basic training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdTzz0v9Cpf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\"\"\"CrossEntropyLoss does not expect a one-hot encoded vector as the target, but class indices:\n",
        "\n",
        "The input is expected to contain scores for each class.\n",
        "input has to be a 2D Tensor of size (minibatch, C).\n",
        "This criterion expects a class index (0 to C-1) as the target for each value of a 1D tensor of size minibatch#Train\"\"\"\n",
        "\n",
        "lossFunc = nn.CrossEntropyLoss()\n",
        "#lossFunc = nn.BCELoss()\n",
        "#lossFunc = nn.MSELoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "#optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "def train(model, trainloader, optimizer, epochs, device):\n",
        "    #model.train()\n",
        "    n=3\n",
        "    running_loss = 0.0\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          # get the inputs\n",
        "          images=data[0].to(device)\n",
        "          labels=data[1].to(device)\n",
        "\n",
        "          #labels = labels.to(device=device, dtype=torch.int64)\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          outputs = model(images)\n",
        "          loss = lossFunc(outputs, labels)\n",
        "\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item()\n",
        "          if i % n == n-1: \n",
        "              print('[%d, %5d] loss: %.3f' %\n",
        "                    (epoch + 1, (i + 1)*BATCH_SIZE, running_loss / BATCH_SIZE*n))\n",
        "              losses.append(running_loss / BATCH_SIZE*n)\n",
        "              running_loss = 0.0\n",
        "    return losses\n",
        "\n",
        "\n",
        "losses = train(net,trainloader, optimizer, 10, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR8mD4-HUpsT",
        "colab_type": "text"
      },
      "source": [
        "##Long training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFfEZGNoUtKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lossFunc = nn.MSELoss()\n",
        "#lossFunc = nn.BCELoss()\n",
        "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "enc_optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-4)\n",
        "dec_optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "def train(encoder, decoder, enc_optimizer, dec_optimazer, trainloader, epochs, device, losses=[], start_epoch=0, best_epochLoss=99999):\n",
        "    #model.train()\n",
        "    n=4\n",
        "    running_loss = 0.0\n",
        "    for epoch in range(start_epoch, epochs + start_epoch):\n",
        "      epochLoss = 0\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          # get the inputs\n",
        "          images = data[0].to(device) \n",
        "          #labels = labels.to(device=device, dtype=torch.int64)\n",
        "          enc_optimizer.zero_grad()\n",
        "          dec_optimizer.zero_grad()\n",
        "\n",
        "          enc = encoder(images)\n",
        "          pre = decoder(enc)\n",
        "\n",
        "          loss = lossFunc(images, pre)\n",
        "\n",
        "          loss.backward()\n",
        "\n",
        "          enc_optimizer.step()\n",
        "          dec_optimizer.step()\n",
        "\n",
        "          running_loss += loss.item()\n",
        "          if i % n == n-1: \n",
        "              print('[%d, %5d] loss: %.7f' %\n",
        "                    (epoch + 1, (i + 1)*BATCH_SIZE, running_loss / (BATCH_SIZE*n)))\n",
        "              losses.append(running_loss / (BATCH_SIZE*n))\n",
        "              epochLoss+=running_loss\n",
        "              running_loss = 0.0\n",
        "\n",
        "      if epoch==0 : best_epochLoss = epochLoss \n",
        "      if epochLoss < best_epochLoss: best_epochLoss=epochLoss\n",
        "    return epochs + start_epoch, best_epochLoss, losses\n",
        "\n",
        "\n",
        "start_epoch, best_epochLoss, losses = train(encoder, decoder, enc_optimizer, dec_optimizer, trainloader, 50, \n",
        "               device,losses=losses, start_epoch=start_epoch, best_epochLoss=best_epochLoss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McByfrxkYDbn",
        "colab_type": "text"
      },
      "source": [
        "#Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zSczMg3YKUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CHK_PATH = '/content/drive/My Drive/ML/Lenguajes/Pytorch/checkpoints/'\n",
        "def save_checkpoint(state, is_best, filename=CHK_PATH + 'checkpoint.pth.tar'):\n",
        "    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n",
        "    if is_best:\n",
        "        print (\"=> Saving a new best\")\n",
        "        torch.save(state, filename)  # save checkpoint\n",
        "    else:\n",
        "        print (\"=> Loss did not improve\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyUSFGkoYhyF",
        "colab_type": "text"
      },
      "source": [
        "Dentro de la funcion de entrenamiento por ejemplo cada epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8qQf6_tX6yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "      if epoch==0 : best_epochLoss = epochLoss \n",
        "      is_best = bool(epochLoss < best_epochLoss)\n",
        "      # best_epochLoss = torch.FloatTensor(max(epochLoss.numpy(), best_epochLoss.numpy()))\n",
        "      if epochLoss < best_epochLoss: best_epochLoss=epochLoss\n",
        "      save_checkpoint({\n",
        "          'epoch': start_epoch + epoch + 1,\n",
        "          'encoder_dict': encoder.state_dict(),\n",
        "          'decoder_dict': decoder.state_dict(),\n",
        "          'best_epochLoss': best_epochLoss,\n",
        "          'losses': losses\n",
        "      }, is_best)\n",
        "      print(\"[\" + str(epochLoss) + \",\" + str(best_epochLoss) + \"]\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqHeuqdjZJl3",
        "colab_type": "text"
      },
      "source": [
        "#Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQmK1RJ7ZMKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, testloader, device, display=False):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data\n",
        "          outputs = model(images.to(device))\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          _, correctLabel = torch.max(labels.to(device), 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == correctLabel).sum().item()\n",
        "  if display:\n",
        "    print('Accuracy of the network on the test images: %d %%' % (\n",
        "        100 * correct / total))\n",
        "  return correct/total\n",
        "  \n",
        "test(net, testloader, device, display=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}